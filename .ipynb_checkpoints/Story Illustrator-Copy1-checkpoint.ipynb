{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8118951-7d11-4d30-a461-e30d8ec42395",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Introduction\n",
    "\n",
    "## Premise\n",
    "\n",
    "This is a utility for converting a (text-only) short children's story into a PDF with vivid illustrations for each scene.\n",
    "\n",
    "It first breaks the story down into an XML format laying out the main character, settings, and scenes. Then it takes this XML object and converts each of the scenes into an image with consistent styling, characters, and settings.\n",
    "\n",
    "## Status\n",
    "\n",
    "**It is very much a work in progress!** As of my writing this introduction, not all functionality (e.g. nothing relating to PDFs) is implemented. The primary goal was to practice working on a **concrete application that includes significant prompt engineering**. At this point, the experimental results still leave a lot to be desired, but they perform the basic task of illustrating individual scenes based only on the story's text and do so with some degree of consistency between images.\n",
    "\n",
    "## Internals\n",
    "\n",
    "### XML Format\n",
    "\n",
    "The XML format used to cut up and provide consistent descriptions for the image generation step follows a strict structure, using the xml.etree.ElementTree library. Details of each tag are spelled out in the `Prompts` section below, so I won't go into detail here, but below is the basic structure:\n",
    "\n",
    "```xml\n",
    "<Story>\n",
    "    <Characters>\n",
    "        <Character name=\"John Doe\">{visual description}</Character>\n",
    "        ...\n",
    "    </Characters>\n",
    "    <Settings>\n",
    "        <Setting>{visual description}</Setting>\n",
    "        ...\n",
    "    </Settings>\n",
    "    <Scenes>\n",
    "        <Scene>\n",
    "            <Text>{original text of scene}</Text>\n",
    "            <Setting>{visual description (from a Settings tag child above)}</Setting>\n",
    "            <Action>{visual description (introducing characters with descriptions from Characters tag children above)}</Action> \n",
    "        </Scene>\n",
    "        ...\n",
    "    </Scenes>\n",
    "</Story>\n",
    "```\n",
    "\n",
    "## Usage\n",
    "\n",
    "This is evolving as I continue to implement functionality so I will try to keep this description up to date.\n",
    "\n",
    "The steps are\n",
    "\n",
    "1. Add the story as a text file in the `input` folder (it is a sibling of this file), keeping track of the filename, e.g. \"Little Red Riding Hood\"\n",
    "2. Run all cells\n",
    "3. Add a cell calling `convert_story_to_html_illustration()` on the story's filename, e.g. `convert_story_to_html_illustration(\"Little Red Riding Hood\")`\n",
    "4. Open the `output` folder (also a sibling of this file) in your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e28850-b69e-437d-a500-80417479aa00",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7681ef-1020-4b70-bd49-8e7d428d0dc7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "87061c9d-7796-4b2d-833c-f63be445e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import html\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c5c18c-0df8-4820-b86f-d3289c177baf",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "cf184711-0ad1-47fa-b174-8605adebb68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_node(node: ET.Element) -> ET.Element:\n",
    "    return ET.fromstring(ET.tostring(node))\n",
    "\n",
    "def base64_to_html_img(base64_string: str):\n",
    "    return f'<img src=\"data:image/png;base64,{base64_string}\" alt=\"Image\"/>'\n",
    "\n",
    "def read_input(filename: str) -> str:\n",
    "    with open(f\"input/{filename}\", 'r') as file:\n",
    "        return file.read().strip()\n",
    "\n",
    "def write_output(filename: str, content: str):\n",
    "    with open(f\"output/{filename}\", 'w') as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dea223-7c48-4664-a7ee-fab23916cc6e",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "266fc3e5-0408-4447-a7f1-3854e28d805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key_path = os.path.expanduser('~/openai_api_key')\n",
    "openai_api_key = read_file(openai_api_key_path)\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "9e60ac14-4232-4222-814d-a754ebab1280",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd0d53b-dd77-4a02-9ade-d4c80fb09a45",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "b0ec205a-cd7a-4844-bca2-92fd72aebfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_IMAGE_LIMIT = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe747ac-21e0-48a5-83db-ca055104b9ce",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "f26d8b85-2f10-4a61-9b6a-c7db35516462",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERAL_IMAGE_PROMPT = (\n",
    "    \"Illustrate the following scene as a Matisse oil painting. Paint should cover most of the canvas. It should be painted with broad brushes and bright colors from a basic palate. \" +\n",
    "    \"It should have crisp, well-defined edges. Focus more on characters than setting\"\n",
    ")\n",
    "    \n",
    "def get_image_prompt(image_prompt_xml_string: str) -> str:\n",
    "    return f'{GENERAL_IMAGE_PROMPT}: {image_prompt_xml_string}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "26f85560-3217-43bf-b4e9-05c5a7d1be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "XML_PROMPT = \"\"\"\n",
    "You will take a story from the user and build a structured XML object to describe it. All tag content must be enclosed between open and close tags.\n",
    "The XML root tag contains 3 tags, each described below: <Settings>, <Characters>, and <Scenes>.\n",
    "\n",
    "The <Settings> tag contains a list of <Setting> tags. Each <Setting> tag contains a short description of the appearance of a distinct location\n",
    "in which at least one Scene takes place. The location should be specific enough all the characters in the scene are clearly visible. You should add \n",
    "details that are not specified in the story to make a description that is easier to visualize as long as they do not contradict the story. Be specific \n",
    "about shapes, colors, indoor vs. outdoor, etc., subject to the constraint that it must be between 100 and 150 characters.\n",
    "\n",
    "The <Characters> tag contains a list of <Character> tags. Each <Character> tag contains a visual description of a major character in the story. \n",
    "Be specific around colors, clothing, age, and gender, subject to the constraint that it must be between 150 and 200 characters. Each \n",
    "<Character> tag has an attribute \"name\" that is the character's most commonly used name.\n",
    "\n",
    "The <Scenes> tag contains a list of <Scene> tags. Each <Scene> tag represents a different scene in the story. Each Scene should be a long as possible \n",
    "because you want to minimize the number of Scenes. A new Scene only begins when either (1) the location changes or (2) a chunk of time in the narrative \n",
    "passes without any new action. Moreover, if a scene is shorter than three sentences, it should be combined with the next scene into a single <Scene> tag. \n",
    "A scene should never end in the middle of a conversation. Each <Scene> tag contains 3 subtags each described below: <Text>, <Setting>, and <Action>. \n",
    "The <Text> tag is the substring of the story narrating the Scene. Each <Scene> tag's <Text> tag is disjoint each other <Scene> tags' <Text> tags\n",
    "and they partition the full text of the story. The <Setting> tag is taken from the <Setting> tag (nested in the <Settings> tag) that corresponds to the \n",
    "location of the Scene, copied exactly. If the Scene spans multiple locations, pick the setting in which the longest substring of Text takes place. The \n",
    "<Action> tag visually describes the action in the part of the Scene taking place in the Setting in under 400 characters. The <Action> tag refers to each of the \n",
    "characters by the \"name\" attribute of the corresponding <Character> tag nested in the <Characters> tag, wrapped in the triple brackets, i.e. [[[ and ]]].\n",
    "\n",
    "For all visual descriptions, i.e. the <Setting>, <Character>, and <Action> tags, you should add details that are not specified in the story to make it \n",
    "easier to visualize, but you must not contradict descriptions in the story. Be concise: never waste space on non-visual details.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafba00a-1d08-437a-b4ee-e76d78b938a3",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a802f2-1dc3-49a5-a9a8-9dbb61833759",
   "metadata": {},
   "source": [
    "## XML Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8100cc77-ba16-42c3-bf32-356a623825c4",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "825f5b16-75ed-4917-a281-abd8cedfa7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_character_introduction(character: ET.Element) -> str:\n",
    "    return f'{character.get('name')} ({character.text.strip('.')})'\n",
    "\n",
    "def substitute_character_descriptions(root: ET.Element) -> ET.Element:\n",
    "    '''Modifies input and returns result'''\n",
    "    character_xml_string_map = {character.get('name'): format_character_introduction(character) for character in root.findall('./Characters/Character')}\n",
    "    for description in root.findall('./Scenes/Scene/Action'):\n",
    "        for character_name in character_xml_string_map.keys():\n",
    "            description.text = re.sub(rf'\\[\\[\\[{character_name}\\]\\]\\]', character_xml_string_map.get(character_name), description.text, count=1)\n",
    "        description.text = re.sub(r'(\\[\\[\\[|\\]\\]\\])', '', description.text)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a298a01-112f-4bd2-8e1c-9d5598ed48a8",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "ea685235-aeeb-409e-81ba-9efd40891202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_xml(story_text: str, prompt: str = XML_PROMPT, print_xml: bool = False) -> ET.Element:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": re.sub(r'\\n+', '\\n', story_text)\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    stripped_xml_string = re.sub(r'(?ms)[^<]*(<.*>).*', r'\\1', response.choices[0].message.content)\n",
    "\n",
    "    try:\n",
    "        xml_root = substitute_character_descriptions(ET.fromstring(stripped_xml_string))\n",
    "        if print_xml:\n",
    "            ET.dump(xml_root)\n",
    "        return xml_root\n",
    "    except Exception as e:\n",
    "        if print_xml:\n",
    "            print(f\"Error in XML conversion operation: {e}. Printing XML story in a simplified string format\")\n",
    "            print(stripped_xml_string)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df99fc-4ba3-4c52-9bd9-f4a6f4b89322",
   "metadata": {},
   "source": [
    "## Image Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a082c79-a27b-455e-89b0-6975b263a528",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "4243fafa-0604-4514-a94f-de1d7c96b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image_prompt(scene: ET.Element) -> str:\n",
    "    scene_clone = clone_node(scene)\n",
    "    scene_clone.remove(scene_clone.find('./Text'))\n",
    "    escaped_xml_string = ET.tostring(scene_clone).decode()\n",
    "    whitespace_trimmed_unescaped_xml_string = re.sub(r'(?ms)>\\s*<', '><', html.unescape(escaped_xml_string))\n",
    "    return whitespace_trimmed_unescaped_xml_string\n",
    "\n",
    "def get_all_image_generation_inputs(story: ET.Element) -> list[dict]:\n",
    "    image_prompts = [parse_image_prompt(scene) for scene in story.findall('./Scenes/Scene')]\n",
    "    return [{\n",
    "        \"model\": 'dall-e-3',\n",
    "        \"prompt\": image_prompt,\n",
    "        \"size\": '1024x1024',\n",
    "        \"quality\": \"standard\",\n",
    "        \"response_format\": \"b64_json\",\n",
    "    } for image_prompt in image_prompts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c062e59-4da5-4aa2-9c48-eba669cb86a3",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "0c2f2b1f-d445-425f-901f-3acbcef7daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def convert_xml_to_base64_images_async(story: ET.Element, limit) -> list[str]:\n",
    "    inputs = get_all_image_generation_inputs(story)\n",
    "    if len(inputs) > limit:\n",
    "        raise Exception(f\"The story had {len(image_prompts)} scenes in total, which exceeds the limit of {limit} so it won't run unless you raise the limit. NOTE: The default limit is {DEFAULT_IMAGE_LIMIT}.\")\n",
    "\n",
    "    loop = asyncio.get_running_loop()\n",
    "    tasks = [loop.run_in_executor(None, partial(client.images.generate, **input)) for input in inputs]\n",
    "    responses = await asyncio.gather(*tasks)\n",
    "    base64_strings = [responses[i].data[0].b64_json for i in range(len(responses))]\n",
    "    return base64_strings\n",
    "\n",
    "def convert_xml_to_base64_images(story: ET.Element, limit) -> list[str]:\n",
    "    return asyncio.run(convert_xml_to_base64_images_async(story, limit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60937467-d7e5-46a9-870d-431aaf0a10fd",
   "metadata": {},
   "source": [
    "## HTML Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a934c8-ecbb-46e1-89c3-cad2b2b926a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_xml_and_base64_images_to_html_elements(story: ET.Element, base64_images: str) -> str:\n",
    "    texts = ["
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e6e57b-01dc-4f46-a524-bfa4d45722f5",
   "metadata": {},
   "source": [
    "## Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "3ae534aa-3816-4091-8283-76c70c932b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_story_to_html_illustration(story_filename: str, limit: int = DEFAULT_IMAGE_LIMIT):\n",
    "    story_text = read_input(story_filename)\n",
    "    story = convert_text_to_xml(story_text)\n",
    "    illustrations_base64 = convert_xml_to_base64_images(story, limit)\n",
    "    write_output(f\"{story_filename}.html\", '\\n'.join([base64_to_html_img(base64) for base64 in illustrations_base64]))\n",
    "    print(f\"Operation complete! Open output/{story_filename}.html in your browser to view results\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
