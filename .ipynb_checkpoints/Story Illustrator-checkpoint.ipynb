{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8118951-7d11-4d30-a461-e30d8ec42395",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Introduction\n",
    "\n",
    "## Premise\n",
    "\n",
    "This is a utility for converting a (text-only) short children's story into a PDF with vivid illustrations for each scene.\n",
    "\n",
    "It first breaks the story down into an XML format laying out the main character, settings, and scenes. Then it takes this XML object and converts each of the scenes into an image with consistent styling, characters, and settings.\n",
    "\n",
    "## Status\n",
    "\n",
    "**It is very much a work in progress!** As of my writing this introduction, not all functionality (e.g. nothing relating to PDFs) is implemented. The primary goal was to practice working on a **concrete application that includes significant prompt engineering**. At this point, the experimental results still leave a lot to be desired, but they perform the basic task of illustrating individual scenes based only on the story's text and do so with some degree of consistency between images.\n",
    "\n",
    "## Internals\n",
    "\n",
    "### XML Format\n",
    "\n",
    "The XML format used to cut up and provide consistent descriptions for the image generation step follows a strict structure, using the xml.etree.ElementTree library. Details of each tag are spelled out in the `Prompts` section below, so I won't go into detail here, but below is the basic structure:\n",
    "\n",
    "```xml\n",
    "<Story>\n",
    "    <Characters>\n",
    "        <Character name=\"John Doe\">{visual description}</Character>\n",
    "        ...\n",
    "    </Characters>\n",
    "    <Settings>\n",
    "        <Setting>{visual description}</Setting>\n",
    "        ...\n",
    "    </Settings>\n",
    "    <Scenes>\n",
    "        <Scene>\n",
    "            <Text>{original text of scene}</Text>\n",
    "            <Setting>{visual description (from a Settings tag child above)}</Setting>\n",
    "            <Action>{visual description (introducing characters with descriptions from Characters tag children above)}</Action> \n",
    "        </Scene>\n",
    "        ...\n",
    "    </Scenes>\n",
    "</Story>\n",
    "```\n",
    "\n",
    "## Usage\n",
    "\n",
    "This is evolving as I continue to implement functionality so I will try to keep this description up to date.\n",
    "\n",
    "The steps are\n",
    "\n",
    "1. Paste your OpenAI API key into a blank file at the path `~/openai_api_key`\n",
    "1. Add the story as a text file in the `input` folder (it is a sibling of this file), keeping track of the filename, e.g. \"Little Red Riding Hood\"\n",
    "1. Run all cells\n",
    "1. Add a cell calling `convert_story_to_html_illustration()` on the story's filename, e.g. `convert_story_to_html_illustration(\"Little Red Riding Hood\")`\n",
    "1. Open the `output` folder (also a sibling of this file) in your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e28850-b69e-437d-a500-80417479aa00",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7681ef-1020-4b70-bd49-8e7d428d0dc7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87061c9d-7796-4b2d-833c-f63be445e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "import re\n",
    "import html\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from typing import Any\n",
    "from datetime import datetime\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c5c18c-0df8-4820-b86f-d3289c177baf",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf184711-0ad1-47fa-b174-8605adebb68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_node(node: ET.Element) -> ET.Element:\n",
    "    return ET.fromstring(ET.tostring(node))\n",
    "\n",
    "def base64_to_html_img(base64_string: str):\n",
    "    return f'<img src=\"data:image/png;base64,{base64_string}\"/>'\n",
    "\n",
    "def read_file_from_path(path):\n",
    "    with open(os.path.expanduser(path), 'r', encoding='utf-8') as file:\n",
    "        return file.read().strip()\n",
    "    \n",
    "def read_input(filename: str) -> str:\n",
    "    return read_file_from_path(f\"input/{filename}\")\n",
    "\n",
    "def write_output(filename: str, content: str):\n",
    "    with open(f\"output/{filename}\", 'w') as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dea223-7c48-4664-a7ee-fab23916cc6e",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379442b9-3d01-43db-bfa5-ef0a702490fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebugMap(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(DebugMap, self).__init__(*args, **kwargs)\n",
    "        self.counter_map: dict[str, int] = {}\n",
    "\n",
    "    def debug(self, log_entry_name, debug_item):\n",
    "        entry_dict = {\n",
    "            'item': debug_item,\n",
    "            'timestamp': datetime.now(),\n",
    "        }\n",
    "        if log_entry_name in self:\n",
    "            self.counter_map[log_entry_name] = self.counter_map.get(log_entry_name, 1) + 1\n",
    "            self[f\"{log_entry_name} (#{self.counter_map[log_entry_name]})\"] = entry_dict\n",
    "        else:\n",
    "            self[log_entry_name] = entry_dict\n",
    "\n",
    "    def filter(self, key_pattern):\n",
    "        return {key: self[key] for key in self if bool(re.search(key_pattern, key, re.IGNORECASE))}\n",
    "\n",
    "    def dump(self):\n",
    "        for key in self:\n",
    "            print(f'---KEY: {key}---')\n",
    "            print('---VALUE---')\n",
    "            value = self[key]\n",
    "            if isinstance(value, ET.Element):\n",
    "                ET.dump(value)\n",
    "            else:\n",
    "                print(value)\n",
    "\n",
    "    def get_item(self, key: str):\n",
    "        if not key in self:\n",
    "            return None\n",
    "        return self[key]['item']\n",
    "\n",
    "    def dump_keys(self):\n",
    "        print('\\n'.join(self.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5b3492-19ad-4747-ae1c-142f1ac5263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_map = DebugMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae931d-106a-4958-a229-25c7321d287f",
   "metadata": {},
   "source": [
    "## API Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973a0aea-5088-4eed-9065-5a5a4ad1f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap RPCs to run manual tests without wasting API calls.\n",
    "\n",
    "class ApiWrapper:\n",
    "    def __init__(self, completion_mock: str = None, image_mock: str = None):\n",
    "        self.completion_mock = completion_mock\n",
    "        self.image_mock = image_mock\n",
    "        \n",
    "    def create_completion(self, **kwargs):\n",
    "        if self.completion_mock is None:\n",
    "            response = client.chat.completions.create(**kwargs)\n",
    "            debug_map.debug('Completion raw response (ApiWrapper.create_completion 1)', deepcopy(response))\n",
    "            return response.choices[0].message.content\n",
    "        time.sleep(2)\n",
    "        debug_map.debug('Completion args for mocked RPC (ApiWrapper.create_completion 1)', kwargs)\n",
    "        return self.completion_mock\n",
    "    \n",
    "    def generate_image(self, **kwargs):\n",
    "        if self.image_mock is None:\n",
    "            response = client.images.generate(**kwargs)\n",
    "            debug_map.debug('Image raw response (ApiWrapper.generate_image 1)', deepcopy(response))\n",
    "            return response.data[0].b64_json\n",
    "        time.sleep(2)\n",
    "        debug_map.debug('Image args for mocked RPC (ApiWrapper.generate_image 1)', kwargs)\n",
    "        return self.image_mock\n",
    "\n",
    "    def reset(self):\n",
    "        self.completion_mock = None\n",
    "        self.image_mock = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5545ab-9291-4d4e-9d26-d5135948699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = ApiWrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b7a131-b89b-4188-bda0-28c004539deb",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266fc3e5-0408-4447-a7f1-3854e28d805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = read_file_from_path('~/openai_api_key')\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e60ac14-4232-4222-814d-a754ebab1280",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd0d53b-dd77-4a02-9ade-d4c80fb09a45",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec205a-cd7a-4844-bca2-92fd72aebfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_IMAGE_LIMIT = 12\n",
    "MAX_IMAGES_PER_MINUTE = 5\n",
    "MINUTE_WITH_CUSHION = 90 # Seconds\n",
    "INDIVIDUAL_IMAGE_REQUEST_WAIT = 15 # Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe747ac-21e0-48a5-83db-ca055104b9ce",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26d8b85-2f10-4a61-9b6a-c7db35516462",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERAL_IMAGE_PROMPT = (\n",
    "    \"Illustrate the following scene as a Matisse oil painting. Paint should cover most of the canvas. It should be painted with broad brushes and \" +\n",
    "    \"bright colors from a basic palate. It should have crisp, well-defined edges. Focus more on characters than setting\"\n",
    ")\n",
    "    \n",
    "def get_image_prompt(image_prompt_xml_string: str) -> str:\n",
    "    return f'{GENERAL_IMAGE_PROMPT}: {image_prompt_xml_string}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f85560-3217-43bf-b4e9-05c5a7d1be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "XML_PROMPT = \"\"\"\n",
    "You will take a story from the user and build a structured XML object to describe it. All tag content must be enclosed between open and close tags.\n",
    "The XML root tag contains 3 tags, each described below: <Settings>, <Characters>, and <Scenes>.\n",
    "\n",
    "The <Settings> tag contains a list of <Setting> tags. Each <Setting> tag contains a short description of the appearance of a distinct location\n",
    "in which at least one Scene takes place. The location should be specific enough all the characters in the scene are clearly visible. You should add \n",
    "details that are not specified in the story to make a description that is easier to visualize as long as they do not contradict the story. Be specific \n",
    "about shapes, colors, indoor vs. outdoor, etc., subject to the constraint that it must be between 100 and 150 characters.\n",
    "\n",
    "The <Characters> tag contains a list of <Character> tags. Each <Character> tag contains a visual description of a major character in the story. \n",
    "Be specific around colors, clothing, age, and gender, subject to the constraint that it must be between 150 and 200 characters and do not contradict \n",
    "the story. Each <Character> tag has an attribute \"name\" that is the character's most commonly used name.\n",
    "\n",
    "The <Scenes> tag contains a list of <Scene> tags. Each <Scene> tag represents a different scene in the story. Each Scene should be a long as possible \n",
    "because you want to minimize the number of Scenes. A new Scene only begins when either (1) the location changes or (2) a chunk of time in the narrative \n",
    "passes without any new action. Moreover, if a scene is shorter than three sentences, it should be combined with the next scene into a single <Scene> tag. \n",
    "A scene should never end in the middle of a conversation. Each <Scene> tag contains 3 subtags each described below: <Text>, <Setting>, and <Action>. \n",
    "The <Text> tag is the substring of the story narrating the Scene. Each <Scene> tag's <Text> tag is disjoint each other <Scene> tags' <Text> tags\n",
    "and they partition the full text of the story. The <Setting> tag is taken from the <Setting> tag (nested in the <Settings> tag) that corresponds to the \n",
    "location of the Scene, copied exactly. If the Scene spans multiple locations, pick the setting in which the longest substring of Text takes place. The \n",
    "<Action> tag visually describes the action in the part of the Scene taking place in the Setting in under 400 characters. The <Action> tag refers to each of the \n",
    "characters by the \"name\" attribute of the corresponding <Character> tag nested in the <Characters> tag, wrapped in the triple brackets, i.e. [[[ and ]]].\n",
    "\n",
    "For all visual descriptions, i.e. the <Setting>, <Character>, and <Action> tags, you should add details that are not specified in the story to make it \n",
    "easier to visualize, but you must not contradict descriptions in the story. Be concise: never waste space on non-visual details.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafba00a-1d08-437a-b4ee-e76d78b938a3",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a802f2-1dc3-49a5-a9a8-9dbb61833759",
   "metadata": {},
   "source": [
    "## XML Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8100cc77-ba16-42c3-bf32-356a623825c4",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825f5b16-75ed-4917-a281-abd8cedfa7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_character_introduction(character: ET.Element) -> str:\n",
    "    return f'{character.get('name')} ({character.text.strip('.')})'\n",
    "\n",
    "def substitute_character_descriptions(story_node: ET.Element) -> ET.Element:\n",
    "    '''Modifies input and returns result'''\n",
    "    debug_map.debug('Story node (substitute_character_descriptions 1)', clone_node(story_node))\n",
    "    character_xml_string_map = {character.get('name'): format_character_introduction(character) for character in story_node.findall('./Characters/Character')}\n",
    "    for description in story_node.findall('./Scenes/Scene/Action'):\n",
    "        for character_name in character_xml_string_map.keys():\n",
    "            description.text = re.sub(rf'\\[\\[\\[{character_name}\\]\\]\\]', character_xml_string_map.get(character_name), description.text, count=1)\n",
    "        description.text = re.sub(r'(\\[\\[\\[|\\]\\]\\])', '', description.text)\n",
    "    debug_map.debug('Story node (substitute_character_descriptions 2)', clone_node(story_node))\n",
    "    return story_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a298a01-112f-4bd2-8e1c-9d5598ed48a8",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea685235-aeeb-409e-81ba-9efd40891202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_xml(story_text: str, prompt: str = XML_PROMPT) -> ET.Element:\n",
    "    debug_map.debug('Story text (convert_text_to_xml 1)', story_text)\n",
    "    response_content = api_wrapper.create_completion(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": re.sub(r'\\n+', '\\n', story_text)\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    stripped_xml_string = re.sub(r'(?ms)[^<]*(<.*>).*', r'\\1', response_content)\n",
    "    debug_map.debug('Story stripped XML string (convert_text_to_xml 1)', story_text)\n",
    "    story_node = substitute_character_descriptions(ET.fromstring(stripped_xml_string))\n",
    "    debug_map.debug('Story node (convert_text_to_xml 1)', clone_node(story_node))\n",
    "    return story_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df99fc-4ba3-4c52-9bd9-f4a6f4b89322",
   "metadata": {},
   "source": [
    "## Image Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a082c79-a27b-455e-89b0-6975b263a528",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4243fafa-0604-4514-a94f-de1d7c96b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image_prompt(scene_node: ET.Element) -> str:\n",
    "    scene_clone = clone_node(scene_node)\n",
    "    debug_map.debug('Scene node (parse_image_prompt 1)', scene_clone)\n",
    "    scene_clone.remove(scene_clone.find('./Text'))\n",
    "    escaped_xml_string = ET.tostring(scene_clone).decode()\n",
    "    whitespace_trimmed_unescaped_xml_string = re.sub(r'(?ms)>\\s*<', '><', html.unescape(escaped_xml_string))\n",
    "    debug_map.debug('Image prompt clean XML string (parse_image_prompt 1)', whitespace_trimmed_unescaped_xml_string)\n",
    "    return whitespace_trimmed_unescaped_xml_string\n",
    "\n",
    "def get_all_image_generation_inputs(story_node: ET.Element) -> list[dict]:\n",
    "    debug_map.debug('Story node (get_all_image_generation_inputs 1)', clone_node(story_node))\n",
    "    image_prompts = [parse_image_prompt(scene_node) for scene_node in story_node.findall('./Scenes/Scene')]\n",
    "    return [{\n",
    "        \"model\": 'dall-e-3',\n",
    "        \"prompt\": image_prompt,\n",
    "        \"size\": '1024x1024',\n",
    "        \"quality\": \"standard\",\n",
    "        \"response_format\": \"b64_json\",\n",
    "    } for image_prompt in image_prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23f1061-adac-4297-bf10-c73b6932e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_image_requests(image_requests: list[str]) -> list[list[str]]:\n",
    "    debug_map.debug('Image requests (batch_image_requests 1)', deepcopy(image_requests))\n",
    "    batch_count = math.ceil(len(image_requests) / MAX_IMAGES_PER_MINUTE)\n",
    "    debug_map.debug('Image request batch count (batch_image_requests 1)', batch_count)\n",
    "    return [image_requests[i:min(i+MAX_IMAGES_PER_MINUTE,len(image_requests))] for i in range(0, batch_count, 5)]\n",
    "\n",
    "async def convert_image_request_batch(request_batch: list) -> list[str]:\n",
    "    debug_map.debug('Image prompt batch (convert_image_request_batch 1)', deepcopy(request_batch))\n",
    "    loop = asyncio.get_running_loop()\n",
    "    tasks = [loop.run_in_executor(None, partial(api_wrapper.generate_image, **request)) for request in request_batch]\n",
    "    base64_strings = await asyncio.gather(*tasks)\n",
    "    debug_map.debug('Image batch base64 strings (convert_image_request_batch 1)', deepcopy(base64_strings))\n",
    "    return base64_strings\n",
    "\n",
    "async def convert_requests_to_base64_images_in_batches(image_requests: list[str]) -> list[str]:\n",
    "    image_request_batches = batch_image_requests(image_requests)\n",
    "    debug_map.debug('Image request batches (convert_prompts_to_base64_images_in_batches 1)', deepcopy(image_request_batches))\n",
    "    converted_image_base64_strings = []\n",
    "    wait = 0\n",
    "    while len(image_request_batches) > 0:\n",
    "        await asyncio.sleep(wait)\n",
    "        batch = image_request_batches.pop(0)\n",
    "        converted_image_base64_strings += await convert_image_request_batch(batch)\n",
    "        wait = MINUTE_WITH_CUSHION\n",
    "    debug_map.debug('Converted base64 image strings (convert_prompts_to_base64_images_in_batches 1)', deepcopy(converted_image_base64_strings))\n",
    "        \n",
    "    return converted_image_base64_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880aeb05-0baa-4413-957d-787c27928ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def convert_prompts_to_base64_images_individually(image_requests: list[str]) -> list[str]:\n",
    "    converted_image_base64_strings = []\n",
    "    wait = 0\n",
    "    for request in image_requests:\n",
    "        await asyncio.sleep(wait)\n",
    "        converted_image_base64_strings.append(api_wrapper.generate_image(**request))\n",
    "        wait = INDIVIDUAL_IMAGE_REQUEST_WAIT\n",
    "    debug_map.debug('Converted base64 image strings (convert_prompts_to_base64_images_individually 1)', deepcopy(converted_image_base64_strings))\n",
    "        \n",
    "    return converted_image_base64_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c062e59-4da5-4aa2-9c48-eba669cb86a3",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2f2b1f-d445-425f-901f-3acbcef7daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def convert_xml_to_base64_images_async(story_node: ET.Element, limit, batch_requests: bool) -> list[str]:\n",
    "    debug_map.debug('Story node (convert_xml_to_base64_images_async 1)', clone_node(story_node))\n",
    "    image_requests = get_all_image_generation_inputs(story_node)\n",
    "    debug_map.debug('Image requests (convert_xml_to_base64_images_async 1)', deepcopy(image_requests))\n",
    "    if len(image_requests) > limit:\n",
    "        raise Exception(f\"The story had {len(image_requests)} scenes in total, which exceeds the limit of {limit} so it won't run unless you raise the limit. NOTE: The default limit is {DEFAULT_IMAGE_LIMIT}.\")\n",
    "\n",
    "    converted_image_base64_strings = await (convert_requests_to_base64_images_in_batches(image_requests) if batch_requests else convert_prompts_to_base64_images_individually(image_requests))\n",
    "    debug_map.debug('Converted base64 image strings (convert_xml_to_base64_images_async 1)', deepcopy(converted_image_base64_strings))\n",
    "        \n",
    "    return converted_image_base64_strings\n",
    "\n",
    "def convert_xml_to_base64_images(story_node: ET.Element, limit: int, batch_requests: bool = False) -> list[str]:\n",
    "    debug_map.debug('Story node (convert_xml_to_base64_images 1)', clone_node(story_node))\n",
    "    debug_map.debug('Image limit (convert_xml_to_base64_images 1)', limit)\n",
    "    return asyncio.run(convert_xml_to_base64_images_async(story_node, limit, batch_requests))\n",
    "\n",
    "\n",
    "### TEST ALL THIS WITH DUMMY CALLS TO API!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60937467-d7e5-46a9-870d-431aaf0a10fd",
   "metadata": {},
   "source": [
    "## HTML Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3780fa-d67d-4302-8765-779d8a521121",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f08af51-1c4d-4a1f-9506-020370dc2e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEAD_TAG= \"\"\"\n",
    "<head>\n",
    "    <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n",
    "    <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n",
    "    <link href=\"https://fonts.googleapis.com/css2?family=Ruge+Boogie&display=swap\" rel=\"stylesheet\">\n",
    "    <style>\n",
    "        .container {\n",
    "            display: flex;\n",
    "            justify-content: center;\n",
    "            padding: 150px;\n",
    "            background-image: url('../assets/old_paper.jpg');\n",
    "            background-size: cover;\n",
    "        }\n",
    "        \n",
    "        .page {\n",
    "            display: flex;\n",
    "            flex-direction: column;\n",
    "            align-items: center;\n",
    "            gap: .2in;\n",
    "            width: 1024px;\n",
    "        }\n",
    "        \n",
    "        .text {\n",
    "            font-size: .2in;\n",
    "            font-family: \"Ruge Boogie\", cursive;\n",
    "            font-weight: 600;\n",
    "            width: 60%;\n",
    "            text-align: center;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fa5ab2-eb63-4035-a245-7eb1db607ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_scene_text_and_base64_image_into_html(scene_text: str, base64_image: str) -> str:\n",
    "    debug_map.debug('Scene text (combine_scene_text_and_base64_image_into_html 1)', scene_text)\n",
    "    debug_map.debug('Base64 image (combine_scene_text_and_base64_image_into_html 1)', base64_image)\n",
    "    return f\"\"\"\n",
    "<div class=\"container\">\n",
    "    <div class=\"page\">\n",
    "        <div class=\"illustration\">{base64_to_html_img(base64_image)}</div>\n",
    "        <div class=\"text\">{scene_text}</div>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3be644-d96e-4420-8685-694faaa56038",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a934c8-ecbb-46e1-89c3-cad2b2b926a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_xml_and_base64_images_to_html_book_pages(story_node: ET.Element, base64_images: list[str]) -> list[str]:\n",
    "    debug_map.debug('Story node (convert_xml_and_base64_images_to_html_book_pages 1)', clone_node(story_node))\n",
    "    debug_map.debug('Base64 images (convert_xml_and_base64_images_to_html_book_pages 1)', deepcopy(base64_images))\n",
    "    scene_texts = [text_node.text for text_node in story_node.findall('./Scenes/Scene/Text')]\n",
    "    assert len(scene_texts) == len(base64_images), f\"The number of scenes in the story ({len(scene_texts)}) did not match the number of base64 illustrations ({len(base64_images)})\"\n",
    "    \n",
    "    page_htmls = [combine_scene_text_and_base64_image_into_html(st, bi) for st, bi in zip(scene_texts, base64_images)]\n",
    "    debug_map.debug('Page HTMLs (convert_xml_and_base64_images_to_html_book_pages 1)', deepcopy(page_htmls))\n",
    "    return page_htmls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e6e57b-01dc-4f46-a524-bfa4d45722f5",
   "metadata": {},
   "source": [
    "## Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae534aa-3816-4091-8283-76c70c932b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_story_to_html_illustration(story_filename: str, limit: int = DEFAULT_IMAGE_LIMIT):\n",
    "    debug_map.debug('Story filename (convert_story_to_html_illustration 1)', story_filename)\n",
    "    story_text = read_input(story_filename)\n",
    "    debug_map.debug('Story text (convert_story_to_html_illustration 1)', story_text)\n",
    "    story_node = convert_text_to_xml(story_text)\n",
    "    debug_map.debug('Story node (convert_story_to_html_illustration 1)', clone_node(story_node))\n",
    "    illustrations_base64 = convert_xml_to_base64_images(story_node, limit)\n",
    "    debug_map.debug('Illustrations as base64 images (convert_story_to_html_illustration 1)', deepcopy(illustrations_base64))\n",
    "        \n",
    "    html_book_pages = convert_xml_and_base64_images_to_html_book_pages(story_node, illustrations_base64)\n",
    "    debug_map.debug('HTML book pages (convert_story_to_html_illustration 1)', deepcopy(html_book_pages))\n",
    "    \n",
    "    write_output(f\"{story_filename}.html\", HEAD_TAG + '<hr />'.join(html_book_pages))\n",
    "    print(f\"Operation complete! Open output/{story_filename}.html in your browser to view results\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c75543-11ec-4b29-8a8c-40a78f41cf5e",
   "metadata": {},
   "source": [
    "## Manual Testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
