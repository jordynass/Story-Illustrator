{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8118951-7d11-4d30-a461-e30d8ec42395",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Introduction\n",
    "\n",
    "## Premise\n",
    "\n",
    "This is a utility for converting a (text-only) short children's story into a PDF with vivid illustrations for each scene.\n",
    "\n",
    "It first breaks the story down into an XML format laying out the main character, settings, and scenes. Then it takes this XML object and converts each of the scenes into an image with consistent styling, characters, and settings.\n",
    "\n",
    "## Status\n",
    "\n",
    "**It is very much a work in progress!** As of my writing this introduction, not all functionality (e.g. nothing relating to PDFs) is implemented. The primary goal was to practice working on a **concrete application that includes significant prompt engineering**. At this point, the experimental results still leave a lot to be desired, but they perform the basic task of illustrating individual scenes based only on the story's text and do so with some degree of consistency between images.\n",
    "\n",
    "## Internals\n",
    "\n",
    "### XML Format\n",
    "\n",
    "The XML format used to cut up and provide consistent descriptions for the image generation step follows a strict structure, using the xml.etree.ElementTree library. Details of each tag are spelled out in the `Prompts` section below, so I won't go into detail here, but below is the basic structure:\n",
    "\n",
    "```xml\n",
    "<Story>\n",
    "    <Characters>\n",
    "        <Character name=\"John Doe\">{visual description}</Character>\n",
    "        ...\n",
    "    </Characters>\n",
    "    <Settings>\n",
    "        <Setting>{visual description}</Setting>\n",
    "        ...\n",
    "    </Settings>\n",
    "    <Scenes>\n",
    "        <Scene>\n",
    "            <Text>{original text of scene}</Text>\n",
    "            <Setting>{visual description (from a Settings tag child above)}</Setting>\n",
    "            <Action>{visual description (introducing characters with descriptions from Characters tag children above)}</Action> \n",
    "        </Scene>\n",
    "        ...\n",
    "    </Scenes>\n",
    "</Story>\n",
    "```\n",
    "\n",
    "## Usage\n",
    "\n",
    "This is evolving as I continue to implement functionality so I will try to keep this description up to date.\n",
    "\n",
    "The steps are\n",
    "\n",
    "1. Add the story as a text file in the `input` folder (it is a sibling of this file), keeping track of the filename, e.g. \"Little Red Riding Hood\"\n",
    "2. Run all cells\n",
    "3. Add a cell calling `convert_story_to_html_illustration()` on the story's filename, e.g. `convert_story_to_html_illustration(\"Little Red Riding Hood\")`\n",
    "4. Open the `output` folder (also a sibling of this file) in your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e28850-b69e-437d-a500-80417479aa00",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7681ef-1020-4b70-bd49-8e7d428d0dc7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "87061c9d-7796-4b2d-833c-f63be445e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "import re\n",
    "import html\n",
    "import os\n",
    "import math\n",
    "from copy import deepcopy\n",
    "from typing import Any\n",
    "from datetime import datetime\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c5c18c-0df8-4820-b86f-d3289c177baf",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "cf184711-0ad1-47fa-b174-8605adebb68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_node(node: ET.Element) -> ET.Element:\n",
    "    return ET.fromstring(ET.tostring(node))\n",
    "\n",
    "def base64_to_html_img(base64_string: str):\n",
    "    return f'<img src=\"data:image/png;base64,{base64_string}\"/>'\n",
    "\n",
    "def read_file_from_path(path):\n",
    "    with open(os.path.expanduser(path), 'r') as file:\n",
    "        return file.read().strip()\n",
    "    \n",
    "def read_input(filename: str) -> str:\n",
    "    return read_file_from_path(f\"input/{filename}\")\n",
    "\n",
    "def write_output(filename: str, content: str):\n",
    "    with open(f\"output/{filename}\", 'w') as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dea223-7c48-4664-a7ee-fab23916cc6e",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "379442b9-3d01-43db-bfa5-ef0a702490fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebugMap(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(DebugMap, self).__init__(*args, **kwargs)\n",
    "        self.counter_map: dict[str, int] = {}\n",
    "\n",
    "    def debug(self, log_entry_name, debug_item):\n",
    "        entry_dict = {\n",
    "            'item': debug_item,\n",
    "            'timestamp': datetime.now(),\n",
    "            'asyncio time': asyncio.get_running_loop().time(),\n",
    "        }\n",
    "        if log_entry_name in self:\n",
    "            self.counter_map[log_entry_name] = self.counter_map.get(log_entry_name, 1) + 1\n",
    "            self[f\"{log_entry_name} (#{self.counter_map[log_entry_name]})\"] = entry_dict\n",
    "        else:\n",
    "            self[log_entry_name] = entry_dict\n",
    "\n",
    "    def filter(self, key_pattern):\n",
    "        return {key: self[key] for key in self if bool(re.search(key_pattern, key, re.IGNORECASE))}\n",
    "\n",
    "    def dump(self):\n",
    "        for key in self:\n",
    "            print(f'---KEY: {key}---')\n",
    "            print('---VALUE---')\n",
    "            value = self[key]\n",
    "            if isinstance(value, ET.Element):\n",
    "                ET.dump(value)\n",
    "            else:\n",
    "                print(value)\n",
    "\n",
    "    def get_item(self, key: str):\n",
    "        if not key in self:\n",
    "            return None\n",
    "        return self[key]['item']\n",
    "\n",
    "    def dump_keys(self):\n",
    "        print('\\n'.join(self.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5a5b3492-19ad-4747-ae1c-142f1ac5263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_map = DebugMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae931d-106a-4958-a229-25c7321d287f",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "266fc3e5-0408-4447-a7f1-3854e28d805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = read_file_from_path('~/openai_api_key')\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9e60ac14-4232-4222-814d-a754ebab1280",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd0d53b-dd77-4a02-9ade-d4c80fb09a45",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b0ec205a-cd7a-4844-bca2-92fd72aebfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_IMAGE_LIMIT = 12\n",
    "MAX_IMAGES_PER_MINUTE = 5\n",
    "MINUTE_WITH_CUSHION = 90 # Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe747ac-21e0-48a5-83db-ca055104b9ce",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f26d8b85-2f10-4a61-9b6a-c7db35516462",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERAL_IMAGE_PROMPT = (\n",
    "    \"Illustrate the following scene as a Matisse oil painting. Paint should cover most of the canvas. It should be painted with broad brushes and \" +\n",
    "    \"bright colors from a basic palate. It should have crisp, well-defined edges. Focus more on characters than setting\"\n",
    ")\n",
    "    \n",
    "def get_image_prompt(image_prompt_xml_string: str) -> str:\n",
    "    return f'{GENERAL_IMAGE_PROMPT}: {image_prompt_xml_string}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "26f85560-3217-43bf-b4e9-05c5a7d1be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "XML_PROMPT = \"\"\"\n",
    "You will take a story from the user and build a structured XML object to describe it. All tag content must be enclosed between open and close tags.\n",
    "The XML root tag contains 3 tags, each described below: <Settings>, <Characters>, and <Scenes>.\n",
    "\n",
    "The <Settings> tag contains a list of <Setting> tags. Each <Setting> tag contains a short description of the appearance of a distinct location\n",
    "in which at least one Scene takes place. The location should be specific enough all the characters in the scene are clearly visible. You should add \n",
    "details that are not specified in the story to make a description that is easier to visualize as long as they do not contradict the story. Be specific \n",
    "about shapes, colors, indoor vs. outdoor, etc., subject to the constraint that it must be between 100 and 150 characters.\n",
    "\n",
    "The <Characters> tag contains a list of <Character> tags. Each <Character> tag contains a visual description of a major character in the story. \n",
    "Be specific around colors, clothing, age, and gender, subject to the constraint that it must be between 150 and 200 characters and do not contradict \n",
    "the story. Each <Character> tag has an attribute \"name\" that is the character's most commonly used name.\n",
    "\n",
    "The <Scenes> tag contains a list of <Scene> tags. Each <Scene> tag represents a different scene in the story. Each Scene should be a long as possible \n",
    "because you want to minimize the number of Scenes. A new Scene only begins when either (1) the location changes or (2) a chunk of time in the narrative \n",
    "passes without any new action. Moreover, if a scene is shorter than three sentences, it should be combined with the next scene into a single <Scene> tag. \n",
    "A scene should never end in the middle of a conversation. Each <Scene> tag contains 3 subtags each described below: <Text>, <Setting>, and <Action>. \n",
    "The <Text> tag is the substring of the story narrating the Scene. Each <Scene> tag's <Text> tag is disjoint each other <Scene> tags' <Text> tags\n",
    "and they partition the full text of the story. The <Setting> tag is taken from the <Setting> tag (nested in the <Settings> tag) that corresponds to the \n",
    "location of the Scene, copied exactly. If the Scene spans multiple locations, pick the setting in which the longest substring of Text takes place. The \n",
    "<Action> tag visually describes the action in the part of the Scene taking place in the Setting in under 400 characters. The <Action> tag refers to each of the \n",
    "characters by the \"name\" attribute of the corresponding <Character> tag nested in the <Characters> tag, wrapped in the triple brackets, i.e. [[[ and ]]].\n",
    "\n",
    "For all visual descriptions, i.e. the <Setting>, <Character>, and <Action> tags, you should add details that are not specified in the story to make it \n",
    "easier to visualize, but you must not contradict descriptions in the story. Be concise: never waste space on non-visual details.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafba00a-1d08-437a-b4ee-e76d78b938a3",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a802f2-1dc3-49a5-a9a8-9dbb61833759",
   "metadata": {},
   "source": [
    "## XML Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8100cc77-ba16-42c3-bf32-356a623825c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "825f5b16-75ed-4917-a281-abd8cedfa7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_character_introduction(character: ET.Element) -> str:\n",
    "    return f'{character.get('name')} ({character.text.strip('.')})'\n",
    "\n",
    "def substitute_character_descriptions(story_node: ET.Element) -> ET.Element:\n",
    "    '''Modifies input and returns result'''\n",
    "    debug_map.debug('Story node (substitute_character_descriptions 1)', clone_node(story_node))\n",
    "    character_xml_string_map = {character.get('name'): format_character_introduction(character) for character in story_node.findall('./Characters/Character')}\n",
    "    for description in story_node.findall('./Scenes/Scene/Action'):\n",
    "        for character_name in character_xml_string_map.keys():\n",
    "            description.text = re.sub(rf'\\[\\[\\[{character_name}\\]\\]\\]', character_xml_string_map.get(character_name), description.text, count=1)\n",
    "        description.text = re.sub(r'(\\[\\[\\[|\\]\\]\\])', '', description.text)\n",
    "    debug_map.debug('Story node (substitute_character_descriptions 2)', clone_node(story_node))\n",
    "    return story_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a298a01-112f-4bd2-8e1c-9d5598ed48a8",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ea685235-aeeb-409e-81ba-9efd40891202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_xml(story_text: str, prompt: str = XML_PROMPT) -> ET.Element:\n",
    "    debug_map.debug('Story text (convert_text_to_xml 1)', story_text)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": re.sub(r'\\n+', '\\n', story_text)\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    stripped_xml_string = re.sub(r'(?ms)[^<]*(<.*>).*', r'\\1', response.choices[0].message.content)\n",
    "    debug_map.debug('Story stripped XML string (convert_text_to_xml 1)', story_text)\n",
    "    story_node = substitute_character_descriptions(ET.fromstring(stripped_xml_string))\n",
    "    debug_map.debug('Story node (convert_text_to_xml 1)', clone_node(story_node))\n",
    "    return story_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df99fc-4ba3-4c52-9bd9-f4a6f4b89322",
   "metadata": {},
   "source": [
    "## Image Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a082c79-a27b-455e-89b0-6975b263a528",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4243fafa-0604-4514-a94f-de1d7c96b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image_prompt(scene_node: ET.Element) -> str:\n",
    "    scene_clone = clone_node(scene_node)\n",
    "    debug_map.debug('Scene node (parse_image_prompt 1)', scene_clone)\n",
    "    scene_clone.remove(scene_clone.find('./Text'))\n",
    "    escaped_xml_string = ET.tostring(scene_clone).decode()\n",
    "    whitespace_trimmed_unescaped_xml_string = re.sub(r'(?ms)>\\s*<', '><', html.unescape(escaped_xml_string))\n",
    "    debug_map.debug('Image prompt clean XML string (parse_image_prompt 1)', whitespace_trimmed_unescaped_xml_string)\n",
    "    return whitespace_trimmed_unescaped_xml_string\n",
    "\n",
    "def get_all_image_generation_inputs(story_node: ET.Element) -> list[dict]:\n",
    "    debug_map.debug('Story node (get_all_image_generation_inputs 1)', clone_node(story_node))\n",
    "    image_prompts = [parse_image_prompt(scene_node) for scene_node in story_node.findall('./Scenes/Scene')]\n",
    "    return [{\n",
    "        \"model\": 'dall-e-3',\n",
    "        \"prompt\": image_prompt,\n",
    "        \"size\": '1024x1024',\n",
    "        \"quality\": \"standard\",\n",
    "        \"response_format\": \"b64_json\",\n",
    "    } for image_prompt in image_prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b23f1061-adac-4297-bf10-c73b6932e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_image_prompts(image_prompts: list[str]) -> list[list[str]]:\n",
    "    debug_map.debug('Image prompts (batch_image_prompts 1)', deepcopy(image_prompts))\n",
    "    batch_count = math.ceil(len(image_prompts) / MAX_IMAGES_PER_MINUTE)\n",
    "    debug_map.debug('Image prompt batch count (batch_image_prompts 1)', batch_count)\n",
    "    return [image_prompts[i:i+5] for i in range(batch_count)]\n",
    "\n",
    "async def convert_image_batch(prompt_batch: list[str]) -> list[str]:\n",
    "    debug_map.debug('Image prompt batch (convert_image_batch 1)', deepcopy(prompt_batch))\n",
    "    loop = asyncio.get_running_loop()\n",
    "    tasks = [loop.run_in_executor(None, partial(client.images.generate, **prompt)) for prompt in prompt_batch]\n",
    "    responses = await asyncio.gather(*tasks)\n",
    "    debug_map.debug('Image batch raw responses (convert_image_batch 1)', deepcopy(responses))\n",
    "    base64_strings = [responses[i].data[0].b64_json for i in range(len(responses))]\n",
    "    debug_map.debug('Image batch base64 strings (convert_image_batch 1)', deepcopy(base64_strings))\n",
    "    return base64_strings\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c062e59-4da5-4aa2-9c48-eba669cb86a3",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "0c2f2b1f-d445-425f-901f-3acbcef7daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def convert_xml_to_base64_images_async(story_node: ET.Element, limit) -> list[str]:\n",
    "    debug_map.debug('Story node (convert_xml_to_base64_images_async 1)', clone_node(story_node))\n",
    "    image_prompts = get_all_image_generation_inputs(story_node)\n",
    "    debug_map.debug('Image prompts (convert_xml_to_base64_images_async 1)', deepcopy(image_prompts))\n",
    "    if len(image_prompts) > limit:\n",
    "        raise Exception(f\"The story had {len(image_prompts)} scenes in total, which exceeds the limit of {limit} so it won't run unless you raise the limit. NOTE: The default limit is {DEFAULT_IMAGE_LIMIT}.\")\n",
    "\n",
    "    image_prompt_batches = batch_image_prompts(image_prompts)\n",
    "    converted_image_base64_strings = []\n",
    "    wait = 0\n",
    "    while len(image_prompt_batches) > 0:\n",
    "        await asyncio.sleep(wait)\n",
    "        batch = image_prompt_batches.pop(0)\n",
    "        start_time = asyncio.get_running_loop().time()\n",
    "        converted_image_base64_strings += await convert_image_batch(batch)\n",
    "        elapsed = asyncio.get_running_loop().time() - start_time\n",
    "        # wait = max(0, MINUTE_WITH_CUSHION - elapsed)\n",
    "        wait = MINUTE_WITH_CUSHION\n",
    "    debug_map.debug('Converted base64 image strings (convert_xml_to_base64_images_async 1)', deepcopy(converted_image_base64_strings))\n",
    "        \n",
    "    return converted_image_base64_strings\n",
    "\n",
    "def convert_xml_to_base64_images(story_node: ET.Element, limit) -> list[str]:\n",
    "    debug_map.debug('Story node (convert_xml_to_base64_images 1)', clone_node(story_node))\n",
    "    debug_map.debug('Image limit (convert_xml_to_base64_images 1)', limit)\n",
    "    return asyncio.run(convert_xml_to_base64_images_async(story_node, limit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60937467-d7e5-46a9-870d-431aaf0a10fd",
   "metadata": {},
   "source": [
    "## HTML Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3780fa-d67d-4302-8765-779d8a521121",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "9f08af51-1c4d-4a1f-9506-020370dc2e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEAD_TAG= \"\"\"\n",
    "<head>\n",
    "    <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n",
    "    <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n",
    "    <link href=\"https://fonts.googleapis.com/css2?family=Ruge+Boogie&display=swap\" rel=\"stylesheet\">\n",
    "    <style>\n",
    "        .container {\n",
    "            display: flex;\n",
    "            justify-content: center;\n",
    "            padding: 150px;\n",
    "            background-image: url('../assets/old_paper.jpg');\n",
    "            background-size: cover;\n",
    "        }\n",
    "        \n",
    "        .page {\n",
    "            display: flex;\n",
    "            flex-direction: column;\n",
    "            align-items: center;\n",
    "            gap: .2in;\n",
    "            width: 1024px;\n",
    "        }\n",
    "        \n",
    "        .text {\n",
    "            font-size: .2in;\n",
    "            font-family: \"Ruge Boogie\", cursive;\n",
    "            font-weight: 600;\n",
    "            width: 60%;\n",
    "            text-align: center;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "55fa5ab2-eb63-4035-a245-7eb1db607ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_scene_text_and_base64_image_into_html(scene_text: str, base64_image: str) -> str:\n",
    "    debug_map.debug('Scene text (combine_scene_text_and_base64_image_into_html 1)', scene_text)\n",
    "    debug_map.debug('Base64 image (combine_scene_text_and_base64_image_into_html 1)', base64_image)\n",
    "    return f\"\"\"\n",
    "<div class=\"container\">\n",
    "    <div class=\"page\">\n",
    "        <div class=\"illustration\">{base64_to_html_img(base64_image)}</div>\n",
    "        <div class=\"text\">{scene_text}</div>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3be644-d96e-4420-8685-694faaa56038",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "99a934c8-ecbb-46e1-89c3-cad2b2b926a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_xml_and_base64_images_to_html_book_pages(story_node: ET.Element, base64_images: list[str]) -> list[str]:\n",
    "    debug_map.debug('Story node (convert_xml_and_base64_images_to_html_book_pages 1)', clone_node(story_node))\n",
    "    debug_map.debug('Base64 images (convert_xml_and_base64_images_to_html_book_pages 1)', deepcopy(base64_images))\n",
    "    scene_texts = [text_node.text for text_node in story_node.findall('./Scenes/Scene/Text')]\n",
    "    assert len(scene_texts) == len(base64_images), f\"The number of scenes in the story ({len(scene_texts)}) did not match the number of base64 illustrations ({len(base64_images)})\"\n",
    "    \n",
    "    page_htmls = [combine_scene_text_and_base64_image_into_html(st, bi) for st, bi in zip(scene_texts, base64_images)]\n",
    "    debug_map.debug('Page HTMLs (convert_xml_and_base64_images_to_html_book_pages 1)', deepcopy(page_htmls))\n",
    "    return page_htmls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e6e57b-01dc-4f46-a524-bfa4d45722f5",
   "metadata": {},
   "source": [
    "## Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3ae534aa-3816-4091-8283-76c70c932b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_story_to_html_illustration(story_filename: str, limit: int = DEFAULT_IMAGE_LIMIT):\n",
    "    debug_map.debug('Story filename (convert_story_to_html_illustration 1)', story_filename)\n",
    "    story_text = read_input(story_filename)\n",
    "    debug_map.debug('Story text (convert_story_to_html_illustration 1)', story_text)\n",
    "    story_node = convert_text_to_xml(story_text)\n",
    "    debug_map.debug('Story node (convert_story_to_html_illustration 1)', clone_node(story_node))\n",
    "    illustrations_base64 = convert_xml_to_base64_images(story_node, limit)\n",
    "    debug_map.debug('Illustrations as base64 images (convert_story_to_html_illustration 1)', deepcopy(illustrations_base64))\n",
    "        \n",
    "    html_book_pages = convert_xml_and_base64_images_to_html_book_pages(story_node, illustrations_base64)\n",
    "    debug_map.debug('HTML book pages (convert_story_to_html_illustration 1)', deepcopy(html_book_pages))\n",
    "    \n",
    "    write_output(f\"{story_filename}.html\", HEAD_TAG + '<hr />'.join(html_book_pages))\n",
    "    print(f\"Operation complete! Open output/{story_filename}.html in your browser to view results\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c75543-11ec-4b29-8a8c-40a78f41cf5e",
   "metadata": {},
   "source": [
    "## Manual Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3acddba4-4c16-4e1b-82a5-3c606e2f2ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation complete! Open output/Gingerbread Man (S).html in your browser to view results\n"
     ]
    }
   ],
   "source": [
    "convert_story_to_html_illustration('Gingerbread Man (S)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f31f3883-15df-4e76-a244-0c3e17dffc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Story>\n",
      "    <Settings>\n",
      "        <Setting>A cozy kitchen filled with warm colors, wooden cabinets, and a light breeze drifting through an open window, the oven glowing softly.</Setting>\n",
      "        <Setting>A lush vegetable garden with rich brown soil, green potato leaves, and an old wooden bench where the old couple eventually rests, under a sunny sky.</Setting>\n",
      "        <Setting>A bustling roadside with soft grass on the sides, vibrant wildflowers, and a path surrounded by tall trees, where the gingerbread man continues to run.</Setting>\n",
      "    </Settings>\n",
      "    <Characters>\n",
      "        <Character name=\"Grandfather\">An elderly man with a gray beard and wrinkled skin, dressed in a plaid shirt, brown trousers, and a worn-out hat, with a gentle demeanor.</Character>\n",
      "        <Character name=\"Grandmother\">An old woman with silver hair tied in a bun, wearing a floral apron over a long dress, her hands weathered from years of work, smiling kindly.</Character>\n",
      "        <Character name=\"Little Boy\">A cheerful young boy with curly brown hair, wearing a brightly colored shirt and shorts, his eyes wide with excitement, a hint of mischief in his demeanor.</Character>\n",
      "        <Character name=\"Gingerbread Man\">A lively gingerbread figure decorated with white icing for hair and clothes, with chocolate chips for eyes and a cheeky grin, rolling quickly away.</Character>\n",
      "        <Character name=\"Bear\">A large brown bear with thick fur and a curious face, lumbering after the gingerbread man, its eyes focused and determined, yet appearing somewhat lazy.</Character>\n",
      "        <Character name=\"Well Digger 1\">A robust man with a tan straw hat and a checkered shirt, his face reddened by the sun, wielding a pick with calloused hands.</Character>\n",
      "        <Character name=\"Well Digger 2\">A sturdy man in overalls, with a sunburned complexion and sweat glistening on his forehead, equally determined to pursue the gingerbread man.</Character>\n",
      "        <Character name=\"Ditch Digger 1\">A muscular man with a scruffy beard and work boots, wearing a tank top, holding a spade, looking up with puzzled eyes at the gingerbread man.</Character>\n",
      "        <Character name=\"Ditch Digger 2\">A lean man in dirty work clothes, with a baseball cap turned backward, looking curious yet playful while resting his spade at his feet.</Character>\n",
      "    </Characters>\n",
      "    <Scenes>\n",
      "        <Scene>\n",
      "            <Text>Once upon a time there was an old man, an old woman, and a little boy. One morning the old woman made some gingerbread in the shape of a man. She added icing for his hair and clothes, and little blobs of dough for his nose and eyes. When she put him in the oven to bake, she said to the little boy, \"You watch the gingerbread man while your grandfather and I go out to work in the garden.\" So the old man and the old woman went out and began to dig potatoes, and left the little boy to tend the oven.</Text>\n",
      "            <Setting>A cozy kitchen filled with warm colors, wooden cabinets, and a light breeze drifting through an open window, the oven glowing softly.</Setting>\n",
      "            <Action>The little boy, excited and fidgety, gazes into the oven with wide eyes, while Grandmother (An old woman with silver hair tied in a bun, wearing a floral apron over a long dress, her hands weathered from years of work, smiling kindly) kneads dough nearby, and Grandfather (An elderly man with a gray beard and wrinkled skin, dressed in a plaid shirt, brown trousers, and a worn-out hat, with a gentle demeanor) prepares the garden tools.</Action>\n",
      "        </Scene>\n",
      "        <Scene>\n",
      "            <Text>But he started to daydream, and didn’t watch it all of the time. All of a sudden he heard a noise, and he looked up and the oven door popped open, and out of the oven jumped a gingerbread man, and went rolling along end over end towards the open door of the house. The little boy ran to shut the door, but the gingerbread man was too quick for him and rolled through the door, down the steps, and out into the road long before the little boy could catch him.</Text>\n",
      "            <Setting>A cozy kitchen filled with warm colors, wooden cabinets, and a light breeze drifting through an open window, the oven glowing softly.</Setting>\n",
      "            <Action>The gingerbread man leaps out of the oven, rolling rapidly away as the little boy dashes towards the door, panicked but too slow to catch the fleeting treat.</Action>\n",
      "        </Scene>\n",
      "        <Scene>\n",
      "            <Text>The little boy ran after him as fast as he could manage, crying out to his grandfather and grandmother, who heard the noise, and threw down their spades in the garden to give chase too. The gingerbread man outran all three a long way, and was soon out of sight, while they had to sit down, all out of breath, on a bank to rest.</Text>\n",
      "            <Setting>A lush vegetable garden with rich brown soil, green potato leaves, and an old wooden bench where the old couple eventually rests, under a sunny sky.</Setting>\n",
      "            <Action>Little Boy (A cheerful young boy with curly brown hair, wearing a brightly colored shirt and shorts, his eyes wide with excitement, a hint of mischief in his demeanor) sprints down the steps, breathless, shouting for Grandfather (An elderly man with a gray beard and wrinkled skin, dressed in a plaid shirt, brown trousers, and a worn-out hat, with a gentle demeanor) and Grandmother (An old woman with silver hair tied in a bun, wearing a floral apron over a long dress, her hands weathered from years of work, smiling kindly). They hurriedly drop their tools and stumble after him, panting heavily as the gingerbread man speeds ahead.</Action>\n",
      "        </Scene>\n",
      "        <Scene>\n",
      "            <Text>On went the gingerbread man, and by-and-by he came to two men digging a well who looked up from their work and called out, \"Where ye going, gingerbread man?\" He said, \"I’ve outrun an old man, an old woman, and a little boy - and I can outrun you too-o-o!\" \"You can, can you? We’ll see about that?\" Said they, and so they threw down their picks and ran after him, but couldn’t catch up with him, and soon they had to sit down by the roadside to rest.</Text>\n",
      "            <Setting>A bustling roadside with soft grass on the sides, vibrant wildflowers, and a path surrounded by tall trees, where the gingerbread man continues to run.</Setting>\n",
      "            <Action>As the gingerbread man rolls past the two well diggers, they call out in surprise, then drop their picks and race after him, their faces determined yet filled with frustration as they lag behind.</Action>\n",
      "        </Scene>\n",
      "        <Scene>\n",
      "            <Text>On ran the gingerbread man, and by-and-by he came to two men digging a ditch. \"Where ye going, gingerbread man?\" said they. He said, \"I’ve outrun an old man, an old woman, a little boy, and two well diggers, and I can outrun you too-o-o!\" \"You can, can you? We’ll see about that!\" said they, and they too threw down their spades, and ran after him. The gingerbread man soon outstripped them also, and seeing they could never catch him, gave up the chase and sat down to rest.</Text>\n",
      "            <Setting>A bustling roadside with soft grass on the sides, vibrant wildflowers, and a path surrounded by tall trees, where the gingerbread man continues to run.</Setting>\n",
      "            <Action>With a confident grin, the gingerbread man announces to the ditch diggers, who shout back before rushing after him, abandoning their spades as they too realize they cannot catch him.</Action>\n",
      "        </Scene>\n",
      "        <Scene>\n",
      "            <Text>On went the gingerbread man, and by-and-by he came to a bear. The bear said, \"Where are ye going, gingerbread man?\" He said, \"I’ve outrun an old man, an old woman, a little boy, two well diggers, and two ditch diggers, and I can outrun you too-o-o!\" \"You can, can you?\" Growled the bear. \"We’ll see about that!\" He trotted as fast as his legs could carry him after the gingerbread man, who never stopped to look behind him. Before long the bear was left so far behind that he saw he might as well given up the hunt at the start, so he stretched himself out by the roadside to rest.</Text>\n",
      "            <Setting>A bustling roadside with soft grass on the sides, vibrant wildflowers, and a path surrounded by tall trees, where the gingerbread man continues to run.</Setting>\n",
      "            <Action>The bear lumbers forward, initially eager, but soon realizes he cannot keep pace with the agile gingerbread man, who swiftly rolls away, while the bear gives up and sprawls out on the grass.</Action>\n",
      "        </Scene>\n",
      "    </Scenes>\n",
      "</Story>\n"
     ]
    }
   ],
   "source": [
    "ET.dump(debug_map['Story node (convert_text_to_xml 1)']['item'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
